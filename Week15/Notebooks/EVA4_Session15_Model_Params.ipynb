{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4_Session15_Model_Params.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakgowtham/EVA4/blob/master/Week15/Notebooks/EVA4_Session15_Model_Params.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgWh86GRUHPy",
        "colab_type": "code",
        "outputId": "3c757385-368f-4dec-dd5d-722e2466eda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyjhe1jI-LRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/Dense_Depth')\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from models import modules, net, resnet, densenet, senet\n",
        "import net_mask\n",
        "import loaddata\n",
        "import util\n",
        "import numpy as np\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.image\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "matplotlib.rcParams['image.cmap'] = 'viridis'\n",
        "\n",
        "import pdb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4adolTWE_g27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(encoder='resnet'):\n",
        "    if encoder is 'resnet':\n",
        "        original_model = resnet.resnet50(pretrained = True)\n",
        "        Encoder = modules.E_resnet(original_model) \n",
        "        model = net.model(Encoder, num_features=2048, block_channel = [256, 512, 1024, 2048])\n",
        "    if encoder is 'densenet':\n",
        "        original_model = densenet.densenet161(pretrained=True)\n",
        "        Encoder = modules.E_densenet(original_model)\n",
        "        model = net.model(Encoder, num_features=2208, block_channel = [192, 384, 1056, 2208])\n",
        "    if encoder is 'senet':\n",
        "        original_model = senet.senet154(pretrained='imagenet')\n",
        "        Encoder = modules.E_senet(original_model)\n",
        "        model = net.model(Encoder, num_features=2048, block_channel = [256, 512, 1024, 2048])\n",
        "\n",
        "    return model\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSppTNzG-MRC",
        "colab_type": "code",
        "outputId": "99187cb9-f588-4f70-c402-e192b7281929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_selection = 'resnet'\n",
        "model = define_model(encoder = model_selection)\n",
        "original_model2 = net_mask.drn_d_22(pretrained=False)\n",
        "model2 = net_mask.AutoED(original_model2)  \n",
        " \n",
        "model = torch.nn.DataParallel(model).cuda()\n",
        "model2 = torch.nn.DataParallel(model2).cuda()\n",
        "\n",
        "model.load_state_dict(torch.load('./pretrained_model/model_' + model_selection))\n",
        "model2.load_state_dict(torch.load('./pretrained_model/mask_save'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvOgpBlMA7uo",
        "colab_type": "code",
        "outputId": "0a3bb250-fc35-495e-def1-bc20548c358d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXLTzPGXA_hh",
        "colab_type": "code",
        "outputId": "be76f3c3-5d1e-45ee-8105-6d6cad33eb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(model, input_size=(3, 64, 64))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
            "            Conv2d-5           [-1, 64, 16, 16]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
            "              ReLU-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
            "             ReLU-10           [-1, 64, 16, 16]               0\n",
            "           Conv2d-11          [-1, 256, 16, 16]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 16, 16]             512\n",
            "           Conv2d-13          [-1, 256, 16, 16]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 16, 16]             512\n",
            "             ReLU-15          [-1, 256, 16, 16]               0\n",
            "       Bottleneck-16          [-1, 256, 16, 16]               0\n",
            "           Conv2d-17           [-1, 64, 16, 16]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 16, 16]             128\n",
            "             ReLU-19           [-1, 64, 16, 16]               0\n",
            "           Conv2d-20           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 16, 16]             128\n",
            "             ReLU-22           [-1, 64, 16, 16]               0\n",
            "           Conv2d-23          [-1, 256, 16, 16]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 16, 16]             512\n",
            "             ReLU-25          [-1, 256, 16, 16]               0\n",
            "       Bottleneck-26          [-1, 256, 16, 16]               0\n",
            "           Conv2d-27           [-1, 64, 16, 16]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
            "             ReLU-29           [-1, 64, 16, 16]               0\n",
            "           Conv2d-30           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 16, 16]             128\n",
            "             ReLU-32           [-1, 64, 16, 16]               0\n",
            "           Conv2d-33          [-1, 256, 16, 16]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 16, 16]             512\n",
            "             ReLU-35          [-1, 256, 16, 16]               0\n",
            "       Bottleneck-36          [-1, 256, 16, 16]               0\n",
            "           Conv2d-37          [-1, 128, 16, 16]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
            "             ReLU-39          [-1, 128, 16, 16]               0\n",
            "           Conv2d-40            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-41            [-1, 128, 8, 8]             256\n",
            "             ReLU-42            [-1, 128, 8, 8]               0\n",
            "           Conv2d-43            [-1, 512, 8, 8]          65,536\n",
            "      BatchNorm2d-44            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-45            [-1, 512, 8, 8]         131,072\n",
            "      BatchNorm2d-46            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-47            [-1, 512, 8, 8]               0\n",
            "       Bottleneck-48            [-1, 512, 8, 8]               0\n",
            "           Conv2d-49            [-1, 128, 8, 8]          65,536\n",
            "      BatchNorm2d-50            [-1, 128, 8, 8]             256\n",
            "             ReLU-51            [-1, 128, 8, 8]               0\n",
            "           Conv2d-52            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 8, 8]             256\n",
            "             ReLU-54            [-1, 128, 8, 8]               0\n",
            "           Conv2d-55            [-1, 512, 8, 8]          65,536\n",
            "      BatchNorm2d-56            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-57            [-1, 512, 8, 8]               0\n",
            "       Bottleneck-58            [-1, 512, 8, 8]               0\n",
            "           Conv2d-59            [-1, 128, 8, 8]          65,536\n",
            "      BatchNorm2d-60            [-1, 128, 8, 8]             256\n",
            "             ReLU-61            [-1, 128, 8, 8]               0\n",
            "           Conv2d-62            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-63            [-1, 128, 8, 8]             256\n",
            "             ReLU-64            [-1, 128, 8, 8]               0\n",
            "           Conv2d-65            [-1, 512, 8, 8]          65,536\n",
            "      BatchNorm2d-66            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-67            [-1, 512, 8, 8]               0\n",
            "       Bottleneck-68            [-1, 512, 8, 8]               0\n",
            "           Conv2d-69            [-1, 128, 8, 8]          65,536\n",
            "      BatchNorm2d-70            [-1, 128, 8, 8]             256\n",
            "             ReLU-71            [-1, 128, 8, 8]               0\n",
            "           Conv2d-72            [-1, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-73            [-1, 128, 8, 8]             256\n",
            "             ReLU-74            [-1, 128, 8, 8]               0\n",
            "           Conv2d-75            [-1, 512, 8, 8]          65,536\n",
            "      BatchNorm2d-76            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-77            [-1, 512, 8, 8]               0\n",
            "       Bottleneck-78            [-1, 512, 8, 8]               0\n",
            "           Conv2d-79            [-1, 256, 8, 8]         131,072\n",
            "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
            "             ReLU-81            [-1, 256, 8, 8]               0\n",
            "           Conv2d-82            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 4, 4]             512\n",
            "             ReLU-84            [-1, 256, 4, 4]               0\n",
            "           Conv2d-85           [-1, 1024, 4, 4]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 4, 4]           2,048\n",
            "           Conv2d-87           [-1, 1024, 4, 4]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 4, 4]           2,048\n",
            "             ReLU-89           [-1, 1024, 4, 4]               0\n",
            "       Bottleneck-90           [-1, 1024, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 4, 4]             512\n",
            "             ReLU-93            [-1, 256, 4, 4]               0\n",
            "           Conv2d-94            [-1, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 4, 4]             512\n",
            "             ReLU-96            [-1, 256, 4, 4]               0\n",
            "           Conv2d-97           [-1, 1024, 4, 4]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 4, 4]           2,048\n",
            "             ReLU-99           [-1, 1024, 4, 4]               0\n",
            "      Bottleneck-100           [-1, 1024, 4, 4]               0\n",
            "          Conv2d-101            [-1, 256, 4, 4]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 4, 4]             512\n",
            "            ReLU-103            [-1, 256, 4, 4]               0\n",
            "          Conv2d-104            [-1, 256, 4, 4]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 4, 4]             512\n",
            "            ReLU-106            [-1, 256, 4, 4]               0\n",
            "          Conv2d-107           [-1, 1024, 4, 4]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 4, 4]           2,048\n",
            "            ReLU-109           [-1, 1024, 4, 4]               0\n",
            "      Bottleneck-110           [-1, 1024, 4, 4]               0\n",
            "          Conv2d-111            [-1, 256, 4, 4]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 4, 4]             512\n",
            "            ReLU-113            [-1, 256, 4, 4]               0\n",
            "          Conv2d-114            [-1, 256, 4, 4]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 4, 4]             512\n",
            "            ReLU-116            [-1, 256, 4, 4]               0\n",
            "          Conv2d-117           [-1, 1024, 4, 4]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 4, 4]           2,048\n",
            "            ReLU-119           [-1, 1024, 4, 4]               0\n",
            "      Bottleneck-120           [-1, 1024, 4, 4]               0\n",
            "          Conv2d-121            [-1, 256, 4, 4]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 4, 4]             512\n",
            "            ReLU-123            [-1, 256, 4, 4]               0\n",
            "          Conv2d-124            [-1, 256, 4, 4]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 4, 4]             512\n",
            "            ReLU-126            [-1, 256, 4, 4]               0\n",
            "          Conv2d-127           [-1, 1024, 4, 4]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 4, 4]           2,048\n",
            "            ReLU-129           [-1, 1024, 4, 4]               0\n",
            "      Bottleneck-130           [-1, 1024, 4, 4]               0\n",
            "          Conv2d-131            [-1, 256, 4, 4]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 4, 4]             512\n",
            "            ReLU-133            [-1, 256, 4, 4]               0\n",
            "          Conv2d-134            [-1, 256, 4, 4]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 4, 4]             512\n",
            "            ReLU-136            [-1, 256, 4, 4]               0\n",
            "          Conv2d-137           [-1, 1024, 4, 4]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 4, 4]           2,048\n",
            "            ReLU-139           [-1, 1024, 4, 4]               0\n",
            "      Bottleneck-140           [-1, 1024, 4, 4]               0\n",
            "          Conv2d-141            [-1, 512, 4, 4]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-143            [-1, 512, 4, 4]               0\n",
            "          Conv2d-144            [-1, 512, 2, 2]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-146            [-1, 512, 2, 2]               0\n",
            "          Conv2d-147           [-1, 2048, 2, 2]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 2, 2]           4,096\n",
            "          Conv2d-149           [-1, 2048, 2, 2]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 2, 2]           4,096\n",
            "            ReLU-151           [-1, 2048, 2, 2]               0\n",
            "      Bottleneck-152           [-1, 2048, 2, 2]               0\n",
            "          Conv2d-153            [-1, 512, 2, 2]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-155            [-1, 512, 2, 2]               0\n",
            "          Conv2d-156            [-1, 512, 2, 2]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-158            [-1, 512, 2, 2]               0\n",
            "          Conv2d-159           [-1, 2048, 2, 2]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 2, 2]           4,096\n",
            "            ReLU-161           [-1, 2048, 2, 2]               0\n",
            "      Bottleneck-162           [-1, 2048, 2, 2]               0\n",
            "          Conv2d-163            [-1, 512, 2, 2]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-165            [-1, 512, 2, 2]               0\n",
            "          Conv2d-166            [-1, 512, 2, 2]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-168            [-1, 512, 2, 2]               0\n",
            "          Conv2d-169           [-1, 2048, 2, 2]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 2, 2]           4,096\n",
            "            ReLU-171           [-1, 2048, 2, 2]               0\n",
            "      Bottleneck-172           [-1, 2048, 2, 2]               0\n",
            "        E_resnet-173  [[-1, 256, 16, 16], [-1, 512, 8, 8], [-1, 1024, 4, 4], [-1, 2048, 2, 2]]               0\n",
            "          Conv2d-174           [-1, 1024, 2, 2]       2,097,152\n",
            "     BatchNorm2d-175           [-1, 1024, 2, 2]           2,048\n",
            "          Conv2d-176            [-1, 512, 4, 4]      13,107,200\n",
            "     BatchNorm2d-177            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-178            [-1, 512, 4, 4]               0\n",
            "          Conv2d-179            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-180            [-1, 512, 4, 4]           1,024\n",
            "          Conv2d-181            [-1, 512, 4, 4]      13,107,200\n",
            "     BatchNorm2d-182            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-183            [-1, 512, 4, 4]               0\n",
            "          Conv2d-184            [-1, 256, 8, 8]       3,276,800\n",
            "     BatchNorm2d-185            [-1, 256, 8, 8]             512\n",
            "            ReLU-186            [-1, 256, 8, 8]               0\n",
            "          Conv2d-187            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-188            [-1, 256, 8, 8]             512\n",
            "          Conv2d-189            [-1, 256, 8, 8]       3,276,800\n",
            "     BatchNorm2d-190            [-1, 256, 8, 8]             512\n",
            "            ReLU-191            [-1, 256, 8, 8]               0\n",
            "          Conv2d-192          [-1, 128, 16, 16]         819,200\n",
            "     BatchNorm2d-193          [-1, 128, 16, 16]             256\n",
            "            ReLU-194          [-1, 128, 16, 16]               0\n",
            "          Conv2d-195          [-1, 128, 16, 16]         147,456\n",
            "     BatchNorm2d-196          [-1, 128, 16, 16]             256\n",
            "          Conv2d-197          [-1, 128, 16, 16]         819,200\n",
            "     BatchNorm2d-198          [-1, 128, 16, 16]             256\n",
            "            ReLU-199          [-1, 128, 16, 16]               0\n",
            "          Conv2d-200           [-1, 64, 32, 32]         204,800\n",
            "     BatchNorm2d-201           [-1, 64, 32, 32]             128\n",
            "            ReLU-202           [-1, 64, 32, 32]               0\n",
            "          Conv2d-203           [-1, 64, 32, 32]          36,864\n",
            "     BatchNorm2d-204           [-1, 64, 32, 32]             128\n",
            "          Conv2d-205           [-1, 64, 32, 32]         204,800\n",
            "     BatchNorm2d-206           [-1, 64, 32, 32]             128\n",
            "            ReLU-207           [-1, 64, 32, 32]               0\n",
            "               D-208           [-1, 64, 32, 32]               0\n",
            "          Conv2d-209           [-1, 16, 32, 32]         102,400\n",
            "     BatchNorm2d-210           [-1, 16, 32, 32]              32\n",
            "            ReLU-211           [-1, 16, 32, 32]               0\n",
            "          Conv2d-212           [-1, 16, 32, 32]           2,304\n",
            "     BatchNorm2d-213           [-1, 16, 32, 32]              32\n",
            "          Conv2d-214           [-1, 16, 32, 32]         102,400\n",
            "     BatchNorm2d-215           [-1, 16, 32, 32]              32\n",
            "            ReLU-216           [-1, 16, 32, 32]               0\n",
            "          Conv2d-217           [-1, 16, 32, 32]         204,800\n",
            "     BatchNorm2d-218           [-1, 16, 32, 32]              32\n",
            "            ReLU-219           [-1, 16, 32, 32]               0\n",
            "          Conv2d-220           [-1, 16, 32, 32]           2,304\n",
            "     BatchNorm2d-221           [-1, 16, 32, 32]              32\n",
            "          Conv2d-222           [-1, 16, 32, 32]         204,800\n",
            "     BatchNorm2d-223           [-1, 16, 32, 32]              32\n",
            "            ReLU-224           [-1, 16, 32, 32]               0\n",
            "          Conv2d-225           [-1, 16, 32, 32]         409,600\n",
            "     BatchNorm2d-226           [-1, 16, 32, 32]              32\n",
            "            ReLU-227           [-1, 16, 32, 32]               0\n",
            "          Conv2d-228           [-1, 16, 32, 32]           2,304\n",
            "     BatchNorm2d-229           [-1, 16, 32, 32]              32\n",
            "          Conv2d-230           [-1, 16, 32, 32]         409,600\n",
            "     BatchNorm2d-231           [-1, 16, 32, 32]              32\n",
            "            ReLU-232           [-1, 16, 32, 32]               0\n",
            "          Conv2d-233           [-1, 16, 32, 32]         819,200\n",
            "     BatchNorm2d-234           [-1, 16, 32, 32]              32\n",
            "            ReLU-235           [-1, 16, 32, 32]               0\n",
            "          Conv2d-236           [-1, 16, 32, 32]           2,304\n",
            "     BatchNorm2d-237           [-1, 16, 32, 32]              32\n",
            "          Conv2d-238           [-1, 16, 32, 32]         819,200\n",
            "     BatchNorm2d-239           [-1, 16, 32, 32]              32\n",
            "            ReLU-240           [-1, 16, 32, 32]               0\n",
            "          Conv2d-241           [-1, 64, 32, 32]         102,400\n",
            "     BatchNorm2d-242           [-1, 64, 32, 32]             128\n",
            "             MFF-243           [-1, 64, 32, 32]               0\n",
            "          Conv2d-244          [-1, 128, 32, 32]         409,600\n",
            "     BatchNorm2d-245          [-1, 128, 32, 32]             256\n",
            "          Conv2d-246          [-1, 128, 32, 32]         409,600\n",
            "     BatchNorm2d-247          [-1, 128, 32, 32]             256\n",
            "          Conv2d-248            [-1, 1, 32, 32]           3,201\n",
            "               R-249            [-1, 1, 32, 32]               0\n",
            "           model-250            [-1, 1, 32, 32]               0\n",
            "================================================================\n",
            "Total params: 67,569,473\n",
            "Trainable params: 67,569,473\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 2199023255511.02\n",
            "Params size (MB): 257.76\n",
            "Estimated Total Size (MB): 2199023255768.83\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRBigcs6BGJI",
        "colab_type": "code",
        "outputId": "f2abe1e2-bcda-478e-cabb-ecd19a6c4fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataParallel(\n",
            "  (module): AutoED(\n",
            "    (E): _E(\n",
            "      (base): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (7): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (8): Sequential(\n",
            "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (D): _D(\n",
            "      (up1): _UpProjection(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (up2): _UpProjection(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (up3): _UpProjection(\n",
            "        (conv1): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF6YEHSHFsnj",
        "colab_type": "code",
        "outputId": "e35243ee-833f-492f-ea99-0a2e4f4611ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(original_model2.cuda(), (3,1024,1024))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1       [-1, 16, 1024, 1024]           2,352\n",
            "       BatchNorm2d-2       [-1, 16, 1024, 1024]              32\n",
            "              ReLU-3       [-1, 16, 1024, 1024]               0\n",
            "            Conv2d-4       [-1, 16, 1024, 1024]           2,304\n",
            "       BatchNorm2d-5       [-1, 16, 1024, 1024]              32\n",
            "              ReLU-6       [-1, 16, 1024, 1024]               0\n",
            "            Conv2d-7         [-1, 32, 512, 512]           4,608\n",
            "       BatchNorm2d-8         [-1, 32, 512, 512]              64\n",
            "              ReLU-9         [-1, 32, 512, 512]               0\n",
            "           Conv2d-10         [-1, 64, 256, 256]          18,432\n",
            "      BatchNorm2d-11         [-1, 64, 256, 256]             128\n",
            "             ReLU-12         [-1, 64, 256, 256]               0\n",
            "           Conv2d-13         [-1, 64, 256, 256]          36,864\n",
            "      BatchNorm2d-14         [-1, 64, 256, 256]             128\n",
            "           Conv2d-15         [-1, 64, 256, 256]           2,048\n",
            "      BatchNorm2d-16         [-1, 64, 256, 256]             128\n",
            "             ReLU-17         [-1, 64, 256, 256]               0\n",
            "       BasicBlock-18         [-1, 64, 256, 256]               0\n",
            "           Conv2d-19         [-1, 64, 256, 256]          36,864\n",
            "      BatchNorm2d-20         [-1, 64, 256, 256]             128\n",
            "             ReLU-21         [-1, 64, 256, 256]               0\n",
            "           Conv2d-22         [-1, 64, 256, 256]          36,864\n",
            "      BatchNorm2d-23         [-1, 64, 256, 256]             128\n",
            "             ReLU-24         [-1, 64, 256, 256]               0\n",
            "       BasicBlock-25         [-1, 64, 256, 256]               0\n",
            "           Conv2d-26        [-1, 128, 128, 128]          73,728\n",
            "      BatchNorm2d-27        [-1, 128, 128, 128]             256\n",
            "             ReLU-28        [-1, 128, 128, 128]               0\n",
            "           Conv2d-29        [-1, 128, 128, 128]         147,456\n",
            "      BatchNorm2d-30        [-1, 128, 128, 128]             256\n",
            "           Conv2d-31        [-1, 128, 128, 128]           8,192\n",
            "      BatchNorm2d-32        [-1, 128, 128, 128]             256\n",
            "             ReLU-33        [-1, 128, 128, 128]               0\n",
            "       BasicBlock-34        [-1, 128, 128, 128]               0\n",
            "           Conv2d-35        [-1, 128, 128, 128]         147,456\n",
            "      BatchNorm2d-36        [-1, 128, 128, 128]             256\n",
            "             ReLU-37        [-1, 128, 128, 128]               0\n",
            "           Conv2d-38        [-1, 128, 128, 128]         147,456\n",
            "      BatchNorm2d-39        [-1, 128, 128, 128]             256\n",
            "             ReLU-40        [-1, 128, 128, 128]               0\n",
            "       BasicBlock-41        [-1, 128, 128, 128]               0\n",
            "           Conv2d-42        [-1, 256, 128, 128]         294,912\n",
            "      BatchNorm2d-43        [-1, 256, 128, 128]             512\n",
            "             ReLU-44        [-1, 256, 128, 128]               0\n",
            "           Conv2d-45        [-1, 256, 128, 128]         589,824\n",
            "      BatchNorm2d-46        [-1, 256, 128, 128]             512\n",
            "           Conv2d-47        [-1, 256, 128, 128]          32,768\n",
            "      BatchNorm2d-48        [-1, 256, 128, 128]             512\n",
            "             ReLU-49        [-1, 256, 128, 128]               0\n",
            "       BasicBlock-50        [-1, 256, 128, 128]               0\n",
            "           Conv2d-51        [-1, 256, 128, 128]         589,824\n",
            "      BatchNorm2d-52        [-1, 256, 128, 128]             512\n",
            "             ReLU-53        [-1, 256, 128, 128]               0\n",
            "           Conv2d-54        [-1, 256, 128, 128]         589,824\n",
            "      BatchNorm2d-55        [-1, 256, 128, 128]             512\n",
            "             ReLU-56        [-1, 256, 128, 128]               0\n",
            "       BasicBlock-57        [-1, 256, 128, 128]               0\n",
            "           Conv2d-58        [-1, 512, 128, 128]       1,179,648\n",
            "      BatchNorm2d-59        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-60        [-1, 512, 128, 128]               0\n",
            "           Conv2d-61        [-1, 512, 128, 128]       2,359,296\n",
            "      BatchNorm2d-62        [-1, 512, 128, 128]           1,024\n",
            "           Conv2d-63        [-1, 512, 128, 128]         131,072\n",
            "      BatchNorm2d-64        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-65        [-1, 512, 128, 128]               0\n",
            "       BasicBlock-66        [-1, 512, 128, 128]               0\n",
            "           Conv2d-67        [-1, 512, 128, 128]       2,359,296\n",
            "      BatchNorm2d-68        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-69        [-1, 512, 128, 128]               0\n",
            "           Conv2d-70        [-1, 512, 128, 128]       2,359,296\n",
            "      BatchNorm2d-71        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-72        [-1, 512, 128, 128]               0\n",
            "       BasicBlock-73        [-1, 512, 128, 128]               0\n",
            "           Conv2d-74        [-1, 512, 128, 128]       2,359,296\n",
            "      BatchNorm2d-75        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-76        [-1, 512, 128, 128]               0\n",
            "           Conv2d-77        [-1, 512, 128, 128]       2,359,296\n",
            "      BatchNorm2d-78        [-1, 512, 128, 128]           1,024\n",
            "             ReLU-79        [-1, 512, 128, 128]               0\n",
            "        AvgPool2d-80            [-1, 512, 4, 4]               0\n",
            "           Conv2d-81           [-1, 1000, 4, 4]         513,000\n",
            "================================================================\n",
            "Total params: 16,393,752\n",
            "Trainable params: 16,393,752\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 12.00\n",
            "Forward/backward pass size (MB): 3648.18\n",
            "Params size (MB): 62.54\n",
            "Estimated Total Size (MB): 3722.72\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}